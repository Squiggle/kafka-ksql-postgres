---
version: '2.1'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.4.0
    container_name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
    # Exposes 9092 for external connections to the broker
    # Use kafka:29092 for connections internal on the docker network
    # See https://rmoff.net/2018/08/02/kafka-listeners-explained/ for details
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    

  schema-registry:
    image: confluentinc/cp-schema-registry:5.4.0
    ports:
      - 8081:8081
    container_name: schema-registry
    depends_on:
      - kafka
      - zookeeper
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
      SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 300
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 3
      
  postgres:
    # *-----------------------------*
    # To connect to the DB:
    #   docker exec -it postgres bash -c 'psql -U $POSTGRES_USER $POSTGRES_DB'
    # *-----------------------------*
    image: postgres:11
    container_name: postgres
    ports: 
      - 5432:5432
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=denormalised
    
  kafka-connect-01:
    image: confluentinc/cp-kafka-connect:5.4.0
    container_name: kafka-connect-01
    depends_on:
      zookeeper:
        condition: service_started
      kafka:
        condition: service_started
      postgres:
        condition: service_started
      schema-registry:
        condition: service_healthy
    ports:
      - 8083:8083
    environment:
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_BOOTSTRAP_SERVERS: kafka:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect-01
      CONNECT_GROUP_ID: kafka-connect-group-01
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-group-01-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-group-01-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-group-01-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '1'
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/connectors || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 3

  ksqldb-server:
    image: confluentinc/ksqldb-server:0.6.0
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      kafka:
        condition: service_started
      postgres:
        condition: service_started
      kafka-connect-01:
        condition: service_started
      schema-registry:
        condition: service_healthy
    volumes:
      - ./ksql:/etc/ksql/scripts
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_CONNECT_URL: http://kafka-connect-01:8083
      KSQL_KSQL_QUERIES_FILE: /etc/ksql/scripts/create_streams.sql
      KSQL_KSQL_SINK_REPLICAS: 1
      KSQL_KSQL_SINK_PARTITIONS: 1

  kafka-connect-init:
    image: byrnedo/alpine-curl
    container_name: kafka-connect-init
    depends_on:
      kafka-connect-01:
        condition: service_healthy
    volumes:
      - ./connect:/etc/kafka-connect/scripts
    entrypoint: ["sh", "/etc/kafka-connect/scripts/init.sh"]

  data-producer:
    image: confluentinc/cp-kafkacat
    container_name: data-producer
    depends_on:
      kafka-connect-01:
        condition: service_healthy
    volumes:
      - ./data:/etc/data
    entrypoint: ["sh", "/etc/data/generate.sh"]